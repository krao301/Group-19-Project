{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('words')  \n",
        "nltk.download('indian') \n",
        "english_words = set(nltk.corpus.words.words())  \n",
        "hindi_words = set(nltk.corpus.indian.words('hindi.pos'))  \n",
        "words=0\n",
        "filename = 'predictions_deromanized.txt'  \n",
        "with open(filename, 'r', encoding='utf-8') as file:\n",
        "    text = file.read()    \n",
        "word_list = text.split() \n",
        "words=words+len(word_list)\n",
        "english_word_set = set()\n",
        "english_word=0\n",
        "hindi_word_set = set()\n",
        "hindi_word=0\n",
        "for word in word_list:\n",
        "    if word.lower() in english_words:  \n",
        "        english_word_set.add(word.lower())\n",
        "        #print(word)\n",
        "        english_word+=1\n",
        "    elif all('\\u0900' <= c <= '\\u097F' for c in word):  \n",
        "       hindi_word_set.add(word)      \n",
        "       hindi_word+=1\n",
        "count=0\n",
        "for i, j in zip(word_list, word_list[1: ]):\n",
        "    if i in hindi_word_set and  j in english_word_set:\n",
        "      count+=1\n",
        "    elif i in english_word_set and j in hindi_word_set:\n",
        "      count+=1        \n",
        "cmi=100*((words-(words-english_word-hindi_word)-max(hindi_word,english_word))/(words-(words-english_word-hindi_word)))\n",
        "print(\"code mixing index :\",cmi)\n",
        "mi=(1-((english_word/words)**2+(hindi_word/words)**2))/((english_word/words)**2+(hindi_word/words)**2)\n",
        "print(\"M-index:\" ,mi)\n",
        "ii=count/(words-1)\n",
        "print(\"I-index:\",ii)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uoOwXaPtM4_",
        "outputId": "86194a6b-0e25-4e1c-c232-44bfb6a0c618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/indian.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "code mixing index : 12.070211667527103\n",
            "M-index: 0.5712703596269515\n",
            "I-index: 0.4943598342868416\n"
          ]
        }
      ]
    }
  ]
}